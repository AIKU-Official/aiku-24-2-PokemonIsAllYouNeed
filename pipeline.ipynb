{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‚¬ìš©ì ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"í”¼ì¹´ì¸„ê°€ ì‹¸ìš´ë‹¤\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ìë§‰ ì •ë³´ë¥¼ ì´ìš©í•˜ì—¬ Timeline ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Download from the ğŸ¤— Hub\n",
    "model = SentenceTransformer(\"nlpai-lab/KoE5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# ì°¾ê³ ì í•˜ëŠ” í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ì™€ ì„ë² ë”© ìƒì„±\n",
    "finding_text = [\n",
    "    user_input\n",
    "]\n",
    "finding_embeddings = model.encode(finding_text)\n",
    "\n",
    "# Threshold ì„¤ì •\n",
    "threshold = 0.3  # ì„ê³„ê°’ ì„¤ì •\n",
    "\n",
    "# ìë§‰ íŒŒì¼ ê²½ë¡œ\n",
    "subtitle_folder_path = \"/home/aikusrv03/pokemon/LCY/moogeun/output_folder/\"\n",
    "embedding_cache_folder = \"/home/aikusrv03/pokemon/LCY/minjun/embedding_cache\"  # ìºì‹œ ì €ì¥ ê²½ë¡œ\n",
    "os.makedirs(embedding_cache_folder, exist_ok=True)\n",
    "\n",
    "# ì‹œê°„ í˜•ì‹ í™•ì¸ í•¨ìˆ˜\n",
    "def is_time_format(line):\n",
    "    \"\"\"ì‹œê°„ í˜•ì‹ì¸ì§€ í™•ì¸ (ì˜ˆ: 109.590s ë˜ëŠ” HH:MM:SS)\"\"\"\n",
    "    return re.match(r\"^\\d+(\\.\\d+)?s$\", line.strip()) is not None\n",
    "\n",
    "# íŒŒì¼ ì •ë ¬ í•¨ìˆ˜\n",
    "def extract_number(file_name):\n",
    "    \"\"\"íŒŒì¼ ì´ë¦„ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: '014' ì¶”ì¶œ)\"\"\"\n",
    "    match = re.search(r'\\d+', file_name)\n",
    "    return int(match.group()) if match else float('inf')  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ë¬´í•œëŒ€ ì²˜ë¦¬\n",
    "\n",
    "# ìºì‹œëœ ì„ë² ë”©ì„ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ìƒì„±\n",
    "def load_or_create_embeddings(file_path, cache_path):\n",
    "    if os.path.exists(cache_path):\n",
    "        # ìºì‹œëœ ì„ë² ë”© ë¡œë“œ\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            print(f\"Loading cached embeddings for {file_path}\")\n",
    "            loaded_data = pickle.load(f)\n",
    "            if isinstance(loaded_data, tuple) and len(loaded_data) == 2:\n",
    "                return loaded_data  # (embeddings, subtitles)\n",
    "            else:\n",
    "                raise ValueError(f\"Cached data format invalid: {loaded_data}\")\n",
    "    else:\n",
    "        # ì„ë² ë”© ìƒˆë¡œ ìƒì„±\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        embeddings = []\n",
    "        subtitles = []\n",
    "        current_time = None\n",
    "        current_dialogue = []\n",
    "\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if is_time_format(line):\n",
    "                if current_time and current_dialogue:\n",
    "                    subtitle = \" \".join(current_dialogue)\n",
    "                    subtitle_embedding = model.encode(subtitle)\n",
    "                    embeddings.append((current_time, subtitle_embedding))\n",
    "                    subtitles.append((current_time, subtitle))\n",
    "\n",
    "                current_time = line\n",
    "                current_dialogue = []\n",
    "            else:\n",
    "                current_dialogue.append(line)\n",
    "\n",
    "        if current_time and current_dialogue:\n",
    "            subtitle = \" \".join(current_dialogue)\n",
    "            subtitle_embedding = model.encode(subtitle)\n",
    "            embeddings.append((current_time, subtitle_embedding))\n",
    "            subtitles.append((current_time, subtitle))\n",
    "\n",
    "        # ì„ë² ë”© ìºì‹œì— ì €ì¥\n",
    "        with open(cache_path, \"wb\") as f:\n",
    "            pickle.dump((embeddings, subtitles), f)  # ë‘ ê°œì˜ ê°’ ì €ì¥\n",
    "\n",
    "        return embeddings, subtitles\n",
    "\n",
    "# í´ë” ë‚´ íŒŒì¼ ì •ë ¬\n",
    "file_names = sorted(\n",
    "    [file_name for file_name in os.listdir(subtitle_folder_path) if file_name.endswith(\".txt\")],\n",
    "    key=extract_number\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "results = []\n",
    "# ìë§‰ íŒŒì¼ ìˆœíšŒ (ìˆ«ì ìˆœì„œëŒ€ë¡œ)\n",
    "for file_name in file_names:\n",
    "    print(f\"Processing: {file_name}\")\n",
    "    \n",
    "    file_path = os.path.join(subtitle_folder_path, file_name)\n",
    "    cache_path = os.path.join(embedding_cache_folder, f\"{file_name}.pkl\")  # ìºì‹œ íŒŒì¼ ê²½ë¡œ\n",
    "    \n",
    "    # ìºì‹œëœ ì„ë² ë”© ë¡œë“œ ë˜ëŠ” ìƒì„±\n",
    "    embeddings, subtitles = load_or_create_embeddings(file_path, cache_path)\n",
    "    \n",
    "    # ê° ëŒ€ì‚¬ì™€ finding_text ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    for (time, subtitle_embedding), (time_text, subtitle) in zip(embeddings, subtitles):\n",
    "        similarities = [cosine_similarity([subtitle_embedding], [ft_emb])[0][0] for ft_emb in finding_embeddings]\n",
    "        avg_similarity = sum(similarities) / len(similarities)\n",
    "        \n",
    "        if avg_similarity >= threshold:\n",
    "            results.append(f\"{file_name}\\t{time_text}\\t{subtitle}\")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "for result in results:\n",
    "    print(result)\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "output_file_path = \"subtitles_timeclips.txt\"\n",
    "with open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n",
    "    for result in results:\n",
    "        output_file.write(result + \"\\n\")\n",
    "\n",
    "print(f\"\\ní•„í„°ë§ëœ ê²°ê³¼ê°€ '{output_file_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì´ë¯¸ì§€ ì„ë² ë”©ì„ í™œìš©í•˜ì—¬ í¬ì¼“ëª¬ ì°¾ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í¬ì¼“ëª¬ ì´ë¦„ ë§¤í•‘ íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "pokemon_name_map_file = 'pokemon_name_map.csv'\n",
    "with open(pokemon_name_map_file, 'r') as f:\n",
    "    name_list = f.readlines()\n",
    "    name_list = [x.split('\\t') for x in name_list]\n",
    "\n",
    "# í¬ì¼“ëª¬ í•œê¸€ ì´ë¦„ ëª©ë¡, í¬ì¼“ëª¬ í•œê¸€ to ì˜ì–´ ì´ë¦„ ëª©ë¡\n",
    "pokemon_kor = [x[1] for x in name_list]\n",
    "pokemon_kor_to_eng = dict([(x[1], x[3]) for x in name_list])\n",
    "\n",
    "pokemon_name_korean = None\n",
    "for name in sorted(pokemon_kor, reverse=True):\n",
    "    if name in user_input:\n",
    "        pokemon_name_korean = name\n",
    "        break\n",
    "    \n",
    "if pokemon_name_korean is None:\n",
    "    print(\"í¬ì¼“ëª¬ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "print(pokemon_name_korean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from extract_embedding import extract_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    # ë²¡í„°ì˜ ë‚´ì  ê³„ì‚°\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    # ë²¡í„°ì˜ í¬ê¸°(norm) ê³„ì‚°\n",
    "    norm_a = np.linalg.norm(vec1)\n",
    "    norm_b = np.linalg.norm(vec2)\n",
    "    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "    return dot_product / (norm_a * norm_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì• ë‹ˆë©”ì´ì…˜ì—ì„œ ë‚˜ì˜¨ detection ì´ë¯¸ì§€ ì„ë² ë”© íŒŒì¼ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "embedding_path = '/home/aikusrv03/pokemon/LCY/lcy/openclip/embeddings_flatten_anime_new.txt'\n",
    "with open(embedding_path, 'r') as f:\n",
    "    embedding_list = f.readlines()\n",
    "    embedding_list = [x.split('\\t') for x in embedding_list]\n",
    "    embedding_dict = dict(embedding_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì• ë‹ˆë©”ì´ì…˜ì˜ ì´ë¯¸ì§€ì™€ ë¹„êµí•  target ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "target_pokemon = pokemon_kor_to_eng[pokemon_name_korean]\n",
    "pokemon_image_dir = '/home/aikusrv03/pokemon/LCY/data/image_1026/class'\n",
    "pokemon_image_list = os.listdir(pokemon_image_dir)\n",
    "target_pokemon_image = [name for name in pokemon_image_list if target_pokemon.lower() in name.lower()]\n",
    "print(target_pokemon_image)\n",
    "\n",
    "image_list = [Image.open(os.path.join(pokemon_image_dir, image_name)) for image_name in target_pokemon_image]\n",
    "target_embedings = [extract_embedding(image) for image in image_list]\n",
    "\n",
    "cos_sim_list = []\n",
    "\n",
    "# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "for image_name, embedding in tqdm(embedding_list):\n",
    "    embedding = eval(embedding)\n",
    "    cos_sim_sum = 0\n",
    "    for target_embedding in target_embedings:\n",
    "        target_embedding = target_embedding.detach().numpy()\n",
    "        cos_sim = cosine_similarity(target_embedding, np.array(embedding))\n",
    "        cos_sim_sum += cos_sim\n",
    "    ave_cos_sim = cos_sim_sum / len(target_embedings)\n",
    "    cos_sim_list.append((ave_cos_sim[0], image_name))\n",
    "cos_sim_list = sorted(cos_sim_list, reverse=True)\n",
    "print(cos_sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìœ ì‚¬ë„ ì‹œê°í™”\n",
    "fig, axes = plt.subplots(10, 10, figsize=(20, 25))\n",
    "fig.suptitle(\"Images Sorted by Cosine Similarity\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(Image.open(cos_sim_list[i][1]), cmap='gray')\n",
    "    ax.set_title(f\"Sim: {cos_sim_list[i][0]:.2f}\")\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ë² ë”© threshold\n",
    "threshold = 0.6\n",
    "filtered_cos_sim_list = [data for data in cos_sim_list if data[0] > threshold]\n",
    "\n",
    "sorted_data = sorted(filtered_cos_sim_list, key=lambda x: x[1])\n",
    "\n",
    "print(len(sorted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìë§‰ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "subtitles_timeclips_file_path = 'subtitles_timeclips.txt'\n",
    "subtitles_timelines = []\n",
    "with open(subtitles_timeclips_file_path, 'r') as f:\n",
    "    subtitles_timelines = f.readlines()\n",
    "subtitles_timelines = [(x.split('Pokemon')[1][:3], x.split('\\t')[1].split('.')[0]) for x in subtitles_timelines]\n",
    "subtitles_timelines_dict = {}\n",
    "for key, value in subtitles_timelines:\n",
    "    if key not in subtitles_timelines_dict:\n",
    "        subtitles_timelines_dict[key] = []\n",
    "    subtitles_timelines_dict[key].append(value)\n",
    "\n",
    "print(subtitles_timelines_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from collections import defaultdict\n",
    "\n",
    "def get_second_from_name(file_name):\n",
    "    name = file_name.split('/')[-2]\n",
    "    sec = name.split('sec')[0]\n",
    "    return sec\n",
    "\n",
    "# ì• ë‹ˆë©”ì´ì…˜ timeclip ì¤€ë¹„\n",
    "timeclip_dict = defaultdict(list)\n",
    "\n",
    "current_anime_name = None\n",
    "start_time = -5\n",
    "end_time = -5\n",
    "\n",
    "for data in sorted_data:\n",
    "    file_name = data[1]\n",
    "    anime_name = file_name.split('/')[-3]\n",
    "    second = int(get_second_from_name(file_name))\n",
    "    \n",
    "    if current_anime_name != anime_name:\n",
    "        current_anime_name = anime_name\n",
    "        start_time = -5\n",
    "        end_time = -5\n",
    "    \n",
    "    if second == end_time + 5:\n",
    "        end_time = second\n",
    "    else:\n",
    "        if start_time >= 0:\n",
    "            timeclip_dict[anime_name].append((start_time, end_time))\n",
    "        start_time = second\n",
    "        end_time = second\n",
    "        \n",
    "print(timeclip_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# timeclipì„ ì´ìš©í•´ì„œ ì• ë‹ˆë©”ì´ì…˜ í´ë¦½ ë§Œë“¤ê¸°\n",
    "\n",
    "animation_dir = '/home/aikusrv03/pokemon/LCY/data/[01] Kanto Chapter [01-82]'\n",
    "animation_list = os.listdir(animation_dir)\n",
    "\n",
    "output_video_dir = f'/home/aikusrv03/pokemon/LCY/data/video_output/1223_{pokemon_name_korean}2'\n",
    "os.makedirs(output_video_dir, exist_ok = True)\n",
    "\n",
    "frame_padding_ratio = 1\n",
    "\n",
    "for animation in timeclip_dict.keys():\n",
    "    \n",
    "    print(f\"Processing {animation}...\")\n",
    "    \n",
    "    timeclips = timeclip_dict[animation]\n",
    "    animation_file_name = [x for x in animation_list if animation in x][0]\n",
    "    \n",
    "    animation_num = animation.split(' ')[-1]\n",
    "    \n",
    "    input_video_path = os.path.join(animation_dir, animation_file_name)\n",
    "    \n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)  # ì´ˆë‹¹ í”„ë ˆì„ ìˆ˜\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # ì „ì²´ í”„ë ˆì„ ìˆ˜\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # ì˜ìƒ í­\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # ì˜ìƒ ë†’ì´\n",
    "\n",
    "\n",
    "    if animation_num not in subtitles_timelines_dict:\n",
    "        continue\n",
    "    subtitles_time = subtitles_timelines_dict[animation_num]\n",
    "\n",
    "    frame_pair_list = []\n",
    "\n",
    "    for timeclip in tqdm(timeclips):\n",
    "\n",
    "        start_time, end_time = timeclip\n",
    "        \n",
    "        flag = False\n",
    "        for time in subtitles_time:\n",
    "            if start_time / 10 <= int(time) - 20 <= end_time / 10:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            continue\n",
    "        \n",
    "        start_frame = int(start_time / 10 * fps)\n",
    "        end_frame = int(end_time / 10 * fps)\n",
    "        \n",
    "        start_frame = int(max(0, start_frame - fps  * frame_padding_ratio))\n",
    "        end_frame = int(end_frame + fps  * frame_padding_ratio)\n",
    "        \n",
    "        frame_pair_list.append((start_frame, end_frame))\n",
    "        \n",
    "    if len(frame_pair_list) == 0:\n",
    "        continue\n",
    "\n",
    "    current_frame = 0\n",
    "    frame_pair_idx = 0\n",
    "    start_frame = frame_pair_list[frame_pair_idx][0]\n",
    "    end_frame = frame_pair_list[frame_pair_idx][1]\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if current_frame == start_frame:\n",
    "            video_name = f'{animation}_{start_time}_{end_time}_{start_frame}_{end_frame}.mp4'\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # ì½”ë± ì„¤ì •\n",
    "            out = cv2.VideoWriter(os.path.join(output_video_dir, video_name), fourcc, fps, (width, height))\n",
    "            out.write(frame)\n",
    "        elif current_frame == end_frame:\n",
    "            out.write(frame)\n",
    "            out.release()\n",
    "            frame_pair_idx += 1\n",
    "            if frame_pair_idx >= len(frame_pair_list):\n",
    "                break\n",
    "            start_frame = frame_pair_list[frame_pair_idx][0]\n",
    "            end_frame = frame_pair_list[frame_pair_idx][1]\n",
    "        elif start_frame < current_frame < end_frame:\n",
    "            out.write(frame)\n",
    "\n",
    "        current_frame += 1\n",
    "\n",
    "# ìì› í•´ì œ\n",
    "cap.release()\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapy as media\n",
    "import random\n",
    "\n",
    "video_list = os.listdir(output_video_dir)\n",
    "\n",
    "video_path = os.path.join(output_video_dir, random.choice(video_list))\n",
    "with media.VideoReader(video_path) as r:\n",
    "    fps = r.fps\n",
    "media.show_video(media.read_video(video_path), fps=fps, codec='gif')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
